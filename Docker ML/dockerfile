# Use python as base image
FROM python
# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY ./llama_cpu_server.py /app/llama_cpu_server.py
COPY ./MediChat_medium_quant-unsloth.Q4_K_M.gguf /app/MediChat_medium_quant-unsloth.Q4_K_M.gguf

# Install the needed packages
RUN pip install llama-cpp-python
RUN pip install Flask
RUN pip install gunicorn

# Run llama_cpu_server.py when the container launches
CMD exec gunicorn --bind :$PORT --workers 1 --threads 1 --timeout 0 llama_cpu_server:app
